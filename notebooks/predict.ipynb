{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip -q install ftfy regex tqdm\n",
    "!pip -q install git+https://github.com/openai/CLIP.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Download the private dataset zip\n",
    "# Unzip the dataset into a folder\n",
    "!gdown 1ttmGZdAZJ-4pA9Kz5SMfvff-G_-Xn0uM\n",
    "!unzip -q ./ENTRep_Private_Dataset_Update.zip -d ./ENTRep_Private_Dataset_update/\n",
    "\n",
    "# Download the CSV and related private image data\n",
    "!gdown 1d66ZMIef0HN8kTfsLzLKlgoAA5NXsI2I\n",
    "!unzip ./ENTRep_Track2_Private_Data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# download the pretrained **Vector Field** model\n",
    "!gdown 1KgzoCoaDoFsLYReWHtX-2MdvflrxSGTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# use a trained **Rerank Model** to rerank results\n",
    "!gdown 1d-JhNGHCKGEIc_9vJYJtHwUPGeShJoOC\n",
    "!unzip -q Rerank_model.zip -d convnextbase-ensemble-metalearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T08:21:49.456816Z",
     "iopub.status.busy": "2025-07-02T08:21:49.456545Z",
     "iopub.status.idle": "2025-07-02T08:21:53.914342Z",
     "shell.execute_reply": "2025-07-02T08:21:53.913719Z",
     "shell.execute_reply.started": "2025-07-02T08:21:49.456791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import pickle\n",
    "import warnings\n",
    "import torch.nn.init as init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T08:21:53.915747Z",
     "iopub.status.busy": "2025-07-02T08:21:53.915359Z",
     "iopub.status.idle": "2025-07-02T08:21:53.925859Z",
     "shell.execute_reply": "2025-07-02T08:21:53.925097Z",
     "shell.execute_reply.started": "2025-07-02T08:21:53.915718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embed_dim = 512\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "    def __init__(self, embed_dim, scale=10.0):\n",
    "        super().__init__()\n",
    "        # Fixed random weights for projecting scalar t to higher frequency space\n",
    "        self.W = nn.Parameter(torch.randn(1, embed_dim // 2) * scale, requires_grad=False)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # Ensure t has shape [B, 1]\n",
    "        if t.ndim == 1:\n",
    "            t = t.unsqueeze(-1)\n",
    "        proj = t * self.W  # Shape: [B, D/2]\n",
    "        # Return sinusoidal and cosinusoidal projection: [sin(tW), cos(tW)] → Shape: [B, D]\n",
    "        return torch.cat([torch.sin(proj), torch.cos(proj)], dim=-1)\n",
    "\n",
    "class VectorField(nn.Module):\n",
    "    def __init__(self, dim, t_dim=32, hidden_dim=256, n_heads=4, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.x_norm = nn.LayerNorm(dim)  # Normalize input embeddings\n",
    "        self.time_encoder = GaussianFourierProjection(t_dim)  # Time embedding module\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # Create multiple independent heads (like a lightweight transformer block)\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(dim + t_dim, hidden_dim),     # Project input + time\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.SiLU(),                               # Activation: SiLU \n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Linear(hidden_dim, dim)              # Back to original embedding dimension\n",
    "            ) for _ in range(n_heads)\n",
    "        ])\n",
    "\n",
    "        self.res_weight = nn.Parameter(torch.tensor(1.0))  # Learnable residual scaling\n",
    "        self.out_norm = nn.LayerNorm(dim)  # Final normalization (not applied directly here)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # Use Kaiming initialization (good for ReLU/SiLU)\n",
    "                init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Handle scalar or 1D tensor time input → ensure shape [B, 1]\n",
    "        if not isinstance(t, torch.Tensor):\n",
    "            t = torch.full((x.shape[0], 1), t, device=x.device)\n",
    "        elif t.ndim == 0:\n",
    "            t = t.expand(x.shape[0], 1)\n",
    "        elif t.ndim == 1:\n",
    "            t = t.unsqueeze(-1)\n",
    "\n",
    "        x_normed = self.x_norm(x)                     # Normalize input\n",
    "        t_encoded = self.time_encoder(t.to(x.device)) # Encode time t\n",
    "        inp = torch.cat([x_normed, t_encoded], dim=-1)  # Concatenate along feature dim\n",
    "\n",
    "        # Pass through each head and average their outputs\n",
    "        head_outs = [head(inp) for head in self.heads]\n",
    "        out = torch.mean(torch.stack(head_outs), dim=0)\n",
    "\n",
    "        # Add residual connection scaled by learnable weight\n",
    "        return out + self.res_weight * x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T08:21:54.288811Z",
     "iopub.status.busy": "2025-07-02T08:21:54.288523Z",
     "iopub.status.idle": "2025-07-02T08:21:54.311023Z",
     "shell.execute_reply": "2025-07-02T08:21:54.310402Z",
     "shell.execute_reply.started": "2025-07-02T08:21:54.288788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RerankModel:\n",
    "    def __init__(self, model_dir, device='cuda'):\n",
    "        self.model_dir = Path(model_dir)\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.class_names = [\n",
    "            \"nose-right\", \"nose-left\", \"ear-right\",\n",
    "            \"ear-left\", \"vc-open\", \"vc-closed\", \"throat\"\n",
    "        ]\n",
    "        self.num_classes = len(self.class_names)\n",
    "\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def load_ensemble_models(self):\n",
    "        \"\"\"Load all models from the ensemble directory.\"\"\"\n",
    "        print(\"Loading ensemble models...\")\n",
    "\n",
    "        with open(self.model_dir / 'ensemble_info.pkl', 'rb') as f:\n",
    "            ensemble_info = pickle.load(f)\n",
    "\n",
    "        models = []\n",
    "        model_names = ensemble_info['models']\n",
    "        weights = ensemble_info['weights']\n",
    "\n",
    "        for i, model_name in enumerate(model_names):\n",
    "            print(f\"Loading model {i+1}/{len(model_names)}: {model_name}\")\n",
    "\n",
    "            if 'convnext' in model_name.lower():\n",
    "                base_name = \"convnext_base.fb_in22k_ft_in1k\"\n",
    "            elif 'efficientnet' in model_name.lower():\n",
    "                base_name = \"efficientnet_b4\"\n",
    "            else:\n",
    "                base_name = \"convnext_base.fb_in22k_ft_in1k\"\n",
    "\n",
    "            model = timm.create_model(base_name, pretrained=False, num_classes=self.num_classes)\n",
    "            state_dict = torch.load(self.model_dir / f\"ensemble_model_{i}.pt\", map_location=self.device)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "\n",
    "            models.append({'model': model, 'weight': weights[i], 'name': model_name})\n",
    "\n",
    "        print(f\"Loaded {len(models)} models successfully.\")\n",
    "        return models\n",
    "\n",
    "    def load_test_data(self, csv_path, img_dir):\n",
    "        \"\"\"Load test image paths from CSV file.\"\"\"\n",
    "        test_files = []\n",
    "        with open(csv_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                if row:\n",
    "                    img_name = row[0].strip()\n",
    "                    img_path = Path(img_dir) / img_name\n",
    "                    if img_path.exists():\n",
    "                        test_files.append(str(img_path))\n",
    "                    else:\n",
    "                        print(f\"Warning: Image not found: {img_path}\")\n",
    "\n",
    "        print(f\"Loaded {len(test_files)} test images.\")\n",
    "        return test_files\n",
    "\n",
    "    def get_tta_transforms(self, img_size=224, n_aug=5):\n",
    "        \"\"\"Generate a list of transforms for Test Time Augmentation (TTA).\"\"\"\n",
    "        class ResizeOrPad:\n",
    "            def __init__(self, min_size):\n",
    "                self.min_size = min_size\n",
    "\n",
    "            def __call__(self, img):\n",
    "                w, h = img.size\n",
    "                if w < self.min_size or h < self.min_size:\n",
    "                    scale = self.min_size / min(w, h)\n",
    "                    new_w = int(w * scale)\n",
    "                    new_h = int(h * scale)\n",
    "                    return T.functional.resize(img, (new_h, new_w))\n",
    "                return img\n",
    "\n",
    "        transforms = [\n",
    "            T.Compose([\n",
    "                ResizeOrPad(img_size),\n",
    "                T.Resize((img_size, img_size)),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        ]\n",
    "\n",
    "        import random\n",
    "        for i in range(n_aug - 1):\n",
    "            resize_delta = random.choice([-20, -10, 0, 10, 20])\n",
    "            target_size = max(img_size, img_size + resize_delta)\n",
    "\n",
    "            transforms.append(\n",
    "                T.Compose([\n",
    "                    ResizeOrPad(target_size + 20),\n",
    "                    T.Resize((target_size + 10, target_size + 10)),\n",
    "                    T.CenterCrop(img_size) if i % 2 == 0 else T.RandomCrop(img_size),\n",
    "                    T.RandomApply([\n",
    "                        T.ColorJitter(\n",
    "                            brightness=random.uniform(0.1, 0.2),\n",
    "                            contrast=random.uniform(0.1, 0.2),\n",
    "                            saturation=random.uniform(0.05, 0.15),\n",
    "                            hue=random.uniform(0.02, 0.05)\n",
    "                        )\n",
    "                    ], p=0.8),\n",
    "                    T.RandomChoice([\n",
    "                        T.GaussianBlur(3, sigma=(0.1, 0.5)),\n",
    "                        nn.Identity()\n",
    "                    ]),\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "            )\n",
    "        return transforms\n",
    "\n",
    "    def predict_single_image_tta(self, model, img_path, n_aug=5):\n",
    "        \"\"\"Predict a single image using Test Time Augmentation (TTA).\"\"\"\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        tta_transforms = self.get_tta_transforms(n_aug=n_aug)\n",
    "\n",
    "        aug_probs = []\n",
    "        with torch.no_grad():\n",
    "            for transform in tta_transforms:\n",
    "                img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
    "                output = model(img_tensor)\n",
    "                probs = F.softmax(output, dim=1)\n",
    "                aug_probs.append(probs)\n",
    "\n",
    "        weights = torch.tensor([1.5] + [1.0] * (n_aug - 1)).to(self.device)\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "        final_probs = torch.zeros_like(aug_probs[0])\n",
    "        for i, probs in enumerate(aug_probs):\n",
    "            final_probs += probs * weights[i]\n",
    "\n",
    "        return final_probs.cpu().numpy().squeeze()\n",
    "\n",
    "    def ensemble_predict_batch(self, models, test_files, use_tta=True, batch_size=32):\n",
    "        \"\"\"Predict a batch of images by ensembling multiple models.\"\"\"\n",
    "        predictions = {}\n",
    "        for img_path in test_files:\n",
    "            img_name = Path(img_path).name\n",
    "            all_model_probs = []\n",
    "            model_weights = []\n",
    "\n",
    "            for model_info in models:\n",
    "                model = model_info['model']\n",
    "                weight = model_info['weight']\n",
    "\n",
    "                if use_tta:\n",
    "                    probs = self.predict_single_image_tta(model, img_path, n_aug=3)\n",
    "                else:\n",
    "                    transform = T.Compose([\n",
    "                        T.Resize((224, 224)),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "                    ])\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "                    img_tensor = transform(image).unsqueeze(0).to(self.device)\n",
    "                    with torch.no_grad():\n",
    "                        output = model(img_tensor)\n",
    "                        probs = F.softmax(output, dim=1).cpu().numpy().squeeze()\n",
    "\n",
    "                all_model_probs.append(probs)\n",
    "                model_weights.append(weight ** 2)\n",
    "\n",
    "            model_weights = np.array(model_weights)\n",
    "            model_weights /= model_weights.sum()\n",
    "\n",
    "            final_probs = np.zeros_like(all_model_probs[0])\n",
    "            for i, probs in enumerate(all_model_probs):\n",
    "                final_probs += probs * model_weights[i]\n",
    "\n",
    "            pred_class = np.argmax(final_probs)\n",
    "            predictions[img_name] = int(pred_class)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict_and_save(self, csv_path, img_dir, output_path, use_tta=True):\n",
    "        \"\"\"Run predictions and save the results to a JSON file.\"\"\"\n",
    "        models = self.load_ensemble_models()\n",
    "        test_files = self.load_test_data(csv_path, img_dir)\n",
    "\n",
    "        print(\"\\nStarting prediction...\")\n",
    "        predictions = self.ensemble_predict_batch(models, test_files, use_tta=use_tta)\n",
    "\n",
    "        print(f\"\\nSaving results to {output_path}\")\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(predictions, f, indent=2)\n",
    "\n",
    "        print(f\"Saved {len(predictions)} predictions\")\n",
    "\n",
    "        print(\"\\nSample predictions:\")\n",
    "        for i, (img_name, pred) in enumerate(list(predictions.items())[:5]):\n",
    "            print(f\"  {img_name}: {pred} ({self.class_names[pred]})\")\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T08:22:12.410216Z",
     "iopub.status.busy": "2025-07-02T08:22:12.409669Z",
     "iopub.status.idle": "2025-07-02T08:22:12.416263Z",
     "shell.execute_reply": "2025-07-02T08:22:12.415581Z",
     "shell.execute_reply.started": "2025-07-02T08:22:12.410190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function to preprocess and embed an image \n",
    "def preprocess_and_embed(image_path):\n",
    "    try:\n",
    "        # Load and convert image to RGB\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Image open failed: {e}\")\n",
    "\n",
    "    # Apply CLIP preprocessing and move to device\n",
    "    image = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Generate image embedding using CLIP\n",
    "        emb = model.encode_image(image)\n",
    "\n",
    "        # Check that the embedding has expected shape [1, 512]\n",
    "        if emb.ndim != 2:\n",
    "            raise RuntimeError(f\"Unexpected embedding shape: {emb.shape}\")\n",
    "\n",
    "        # Normalize the embedding vector\n",
    "        emb = emb / emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # Ensure correct dtype before passing to vector field\n",
    "        emb = emb.to(next(vf.parameters()).dtype)\n",
    "\n",
    "        # Apply learned vector field at time t = 0.0\n",
    "        emb_vf = vf(emb, t=torch.tensor([[0.0]], device=emb.device)).squeeze(0).cpu()\n",
    "\n",
    "        # Ensure the output is a 1D vector\n",
    "        if emb_vf.ndim != 1:\n",
    "            raise RuntimeError(f\"VectorField output is not 1D: {emb_vf.shape}\")\n",
    "\n",
    "    return emb_vf  # Final transformed embedding\n",
    "    \n",
    "def rerank_topk_by_class(candidate_names, candidate_scores, predictor, models, img_dir, bonus=0.01):\n",
    "    \"\"\"\n",
    "    Re-rank a list of top-k image candidates by promoting those that share the dominant class.\n",
    "\n",
    "    Args:\n",
    "        candidate_names (List[str]): Top-k image file names to be re-ranked.\n",
    "        candidate_scores (List[float]): Corresponding similarity scores.\n",
    "        predictor (RerankModel): Classifier wrapper to load and use ensemble models.\n",
    "        models (List): List of loaded classification models.\n",
    "        img_dir (str): Path to image directory.\n",
    "        bonus (float): Bonus score to add for images in the dominant class.\n",
    "\n",
    "    Returns:\n",
    "        reranked_names (List[str]): Candidate names sorted by adjusted score.\n",
    "    \"\"\"\n",
    "    name_to_class = {}   # Map image name → predicted class\n",
    "    class_votes = {}     # Count class frequency\n",
    "\n",
    "    # Predict class for each candidate\n",
    "    for img_name in candidate_names:\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        pred_class = predictor.ensemble_predict_batch(models, [img_path], use_tta=False)[img_name]\n",
    "        name_to_class[img_name] = pred_class\n",
    "        class_votes[pred_class] = class_votes.get(pred_class, 0) + 1\n",
    "\n",
    "    # Identify majority class\n",
    "    main_class = max(class_votes, key=class_votes.get)\n",
    "\n",
    "    # Apply bonus score for images in majority class\n",
    "    reranked = []\n",
    "    for name, score in zip(candidate_names, candidate_scores):\n",
    "        bonus_score = bonus if name_to_class[name] == main_class else 0.0\n",
    "        reranked.append((name, score + bonus_score))\n",
    "\n",
    "    # Sort descending by score\n",
    "    reranked = sorted(reranked, key=lambda x: -x[1])\n",
    "    reranked_names = [name for name, _ in reranked]\n",
    "    return reranked_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Retrieval Pipeline Description**\n",
    "\n",
    "Image-to-image retrieval is performed in 4 main steps:\n",
    "\n",
    "1. **Image Loading**: Read all image file names from a CSV file.\n",
    "\n",
    "2. **Embedding Extraction**: Use CLIP + VectorField to compute embeddings for all images.\n",
    "\n",
    "3. **Similarity Search**: For each query image, retrieve top-5 similar images using cosine similarity.\n",
    "\n",
    "4. **Class-based Reranking**: Use an ensemble classifier to predict classes of the top-5 candidates. Images sharing the dominant class receive a score bonus (+0.01) before reranking.\n",
    "\n",
    "The top-1 result after reranking is stored for each query image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T08:22:14.673149Z",
     "iopub.status.busy": "2025-07-02T08:22:14.672542Z",
     "iopub.status.idle": "2025-07-02T08:22:30.145288Z",
     "shell.execute_reply": "2025-07-02T08:22:30.144572Z",
     "shell.execute_reply.started": "2025-07-02T08:22:14.673118Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading ensemble models...\n",
      "Loading model 1/6: convnext_base.fb_in22k_ft_in1k_full\n",
      "Loading model 2/6: convnext_base.fb_in22k_ft_in1k_fold3\n",
      "Loading model 3/6: convnext_base.fb_in22k_ft_in1k_fold1\n",
      "Loading model 4/6: convnext_base.fb_in22k_ft_in1k_fold4\n",
      "Loading model 5/6: convnext_base.fb_in22k_ft_in1k_fold5\n",
      "Loading model 6/6: convnext_base.fb_in22k_ft_in1k_fold2\n",
      "Loaded 6 models successfully.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load pre-trained CLIP model (ViT-B/32) for image embedding\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Initialize the learned time-dependent vector field module\n",
    "vf = VectorField(embed_dim).to(device).float()\n",
    "\n",
    "# Load the pre-trained weights for the vector field\n",
    "vf.load_state_dict(torch.load(\"./vf_model.pth\", map_location=device))\n",
    "vf.eval()  # Set to evaluation mode\n",
    "\n",
    "# Initialize the reranking model used for predicting anatomical regions\n",
    "predictor = RerankModel(model_dir=\"./convnextbase-ensemble-metalearner\")\n",
    "\n",
    "# Load ensemble of classification models from the specified directory\n",
    "models = predictor.load_ensemble_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T08:22:36.514816Z",
     "iopub.status.busy": "2025-07-02T08:22:36.514228Z",
     "iopub.status.idle": "2025-07-02T08:26:34.437752Z",
     "shell.execute_reply": "2025-07-02T08:26:34.437026Z",
     "shell.execute_reply.started": "2025-07-02T08:22:36.514792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Embedded all images\n",
      "Retrieval completed for all images\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read image names from CSV\n",
    "image_dir = \"./ENTRep_Private_Dataset_update/imgs\"  # Path to directory containing test images\n",
    "csv_path = \"i2i.csv\"  # CSV file with image names (1 name per line)\n",
    "\n",
    "with open(csv_path, \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    image_list = [row[0].strip() for row in reader if row]  # List of image file names\n",
    "\n",
    "\n",
    "#Step 2: Compute embeddings for all images\n",
    "# Output: all_embeddings[img_name] = torch.Tensor of shape [D]\n",
    "\n",
    "all_embeddings = {}\n",
    "\n",
    "for img_name in image_list:\n",
    "    img_path = os.path.join(image_dir, img_name)  # Full path to the image\n",
    "    try:\n",
    "        emb = preprocess_and_embed(img_path)  # Generate CLIP+VectorField embedding\n",
    "        all_embeddings[img_name] = emb\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error with {img_name}: {e}\")\n",
    "print(\" Embedded all images\")\n",
    "\n",
    "#Step 3: Filter valid embeddings and stack into a tensor\n",
    "# Output: embeddings: torch.Tensor [N, D], img_names: List[str]\n",
    "valid_img_names = []\n",
    "valid_embeddings = []\n",
    "\n",
    "for name in all_embeddings:\n",
    "    emb = all_embeddings[name]\n",
    "    # Ensure embedding is a 1D torch.Tensor (e.g., shape = [512])\n",
    "    if isinstance(emb, torch.Tensor) and emb.ndim == 1:\n",
    "        valid_img_names.append(name)\n",
    "        valid_embeddings.append(emb)\n",
    "    else:\n",
    "        print(f\"⚠️ Invalid embedding: {name} → {type(emb)}, shape = {getattr(emb, 'shape', None)}\")\n",
    "\n",
    "if not valid_embeddings:\n",
    "    raise ValueError(\"❌ No valid embeddings found!\")\n",
    "\n",
    "# Stack embeddings into a tensor and normalize\n",
    "img_names = valid_img_names\n",
    "embeddings = torch.stack(valid_embeddings)  # Shape: [N, D]\n",
    "embeddings = F.normalize(embeddings, dim=-1)  # Cosine-normalized embeddings\n",
    "\n",
    "\n",
    "# Step 4: Image Retrieval with Class-based Reranking\n",
    "# For each image, find top-5 most similar, then re-rank by majority class\n",
    "retrieval_results = {}\n",
    "\n",
    "for i, query_name in enumerate(img_names):\n",
    "    query_emb = embeddings[i].unsqueeze(0)  # Shape: [1, D]\n",
    "    # Exclude current image to avoid self-matching\n",
    "    others = torch.cat([embeddings[:i], embeddings[i+1:]], dim=0)  # Shape: [N-1, D]\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    sims = (others @ query_emb.T).squeeze()  # Shape: [N-1]\n",
    "\n",
    "    # Retrieve top-5 most similar images\n",
    "    topk = torch.topk(sims, k=5)\n",
    "    topk_indices = topk.indices.tolist()\n",
    "    topk_scores = topk.values.tolist()\n",
    "\n",
    "    # Map indices to actual image names (adjust index if skipped self)\n",
    "    candidate_names = []\n",
    "    candidate_scores = []\n",
    "    for j, idx in enumerate(topk_indices):\n",
    "        idx_adjusted = idx if idx < i else idx + 1\n",
    "        candidate_names.append(img_names[idx_adjusted])\n",
    "        candidate_scores.append(topk_scores[j])\n",
    "\n",
    "    # Re-rank candidates using class prediction\n",
    "    reranked = rerank_topk_by_class(\n",
    "        candidate_names, candidate_scores,\n",
    "        predictor, models, image_dir, bonus=0.01\n",
    "    )\n",
    "\n",
    "    # Save only the top-1 match\n",
    "    retrieval_results[query_name] = reranked[0]\n",
    "print(\"Retrieval completed for all images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T08:27:26.976983Z",
     "iopub.status.busy": "2025-07-02T08:27:26.976679Z",
     "iopub.status.idle": "2025-07-02T08:27:26.982727Z",
     "shell.execute_reply": "2025-07-02T08:27:26.982153Z",
     "shell.execute_reply.started": "2025-07-02T08:27:26.976962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved top-1 retrieval results with rerank to: rerank003.json\n"
     ]
    }
   ],
   "source": [
    "output_json = \"rerank003.json\"\n",
    "# Save results\n",
    "with open(output_json, \"w\") as f:\n",
    "    json.dump(retrieval_results, f, indent=2)\n",
    "print(f\"Saved top-1 retrieval results with rerank to: {output_json}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7714390,
     "sourceId": 12243516,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
